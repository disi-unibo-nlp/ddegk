{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DGCNN"
      ],
      "metadata": {
        "id": "2c9ygtzNN9fJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kQvtvNZlBen"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_s4kUtDVUyhD"
      },
      "outputs": [],
      "source": [
        "fn = 'pc'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISn_ky-RjB9v",
        "nbsphinx": "hidden",
        "outputId": "5c1da43f-39fb-4d78-c666-4dc7a00650af",
        "tags": [
          "CloudRunner"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r",
            "\u001b[K     |▊                               | 10 kB 18.1 MB/s eta 0:00:01\r",
            "\u001b[K     |█▌                              | 20 kB 12.6 MB/s eta 0:00:01\r",
            "\u001b[K     |██▎                             | 30 kB 9.0 MB/s eta 0:00:01\r",
            "\u001b[K     |███                             | 40 kB 8.0 MB/s eta 0:00:01\r",
            "\u001b[K     |███▊                            | 51 kB 5.4 MB/s eta 0:00:01\r",
            "\u001b[K     |████▌                           | 61 kB 5.5 MB/s eta 0:00:01\r",
            "\u001b[K     |█████▎                          | 71 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |██████                          | 81 kB 5.8 MB/s eta 0:00:01\r",
            "\u001b[K     |██████▊                         | 92 kB 6.0 MB/s eta 0:00:01\r",
            "\u001b[K     |███████▌                        | 102 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |████████▎                       | 112 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |█████████                       | 122 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |█████████▉                      | 133 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |██████████▌                     | 143 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |███████████▎                    | 153 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |████████████                    | 163 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |████████████▉                   | 174 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |█████████████▌                  | 184 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |██████████████▎                 | 194 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |███████████████                 | 204 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |███████████████▉                | 215 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |████████████████▋               | 225 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |█████████████████▎              | 235 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |██████████████████              | 245 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |██████████████████▉             | 256 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |███████████████████▋            | 266 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |████████████████████▎           | 276 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |█████████████████████           | 286 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |█████████████████████▉          | 296 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |██████████████████████▋         | 307 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |███████████████████████▍        | 317 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |████████████████████████        | 327 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |████████████████████████▉       | 337 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |█████████████████████████▋      | 348 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |██████████████████████████▍     | 358 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |███████████████████████████     | 368 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |███████████████████████████▉    | 378 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |████████████████████████████▋   | 389 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |█████████████████████████████▍  | 399 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |██████████████████████████████▏ | 409 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |██████████████████████████████▉ | 419 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |███████████████████████████████▋| 430 kB 5.2 MB/s eta 0:00:01\r",
            "\u001b[K     |████████████████████████████████| 435 kB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 407 kB 40.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.3 MB/s \n",
            "\u001b[?25h  Building wheel for mplleaflet (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# install StellarGraph if running on Google Colab\n",
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  %pip install -q stellargraph[demos]==1.2.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nclCx0pjB9y",
        "nbsphinx": "hidden",
        "tags": [
          "VersionCheck"
        ]
      },
      "outputs": [],
      "source": [
        "# verify that we're using the correct version of StellarGraph for this notebook\n",
        "import stellargraph as sg\n",
        "\n",
        "try:\n",
        "    sg.utils.validate_notebook_version(\"1.2.1\")\n",
        "except AttributeError:\n",
        "    raise ValueError(\n",
        "        f\"This notebook requires StellarGraph version 1.2.1, but a different version {sg.__version__} is installed.  Please see <https://github.com/stellargraph/stellargraph/issues/1172>.\"\n",
        "    ) from None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzIeiIIPjB9z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import networkx as nx\n",
        "\n",
        "import stellargraph as sg\n",
        "from stellargraph.mapper import PaddedGraphGenerator\n",
        "from stellargraph.layer import DeepGraphCNN\n",
        "from stellargraph import StellarGraph\n",
        "\n",
        "from stellargraph import datasets\n",
        "\n",
        "from sklearn import model_selection\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPool1D, Dropout, Flatten\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wfz6uEsjB91"
      },
      "source": [
        "## StellarGraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0fSJonCoVc0"
      },
      "source": [
        "Loading of the dataset. Each graph is converted to a **networkx** graph  and then to a **stellargraph**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvvvyQJb4a_b"
      },
      "outputs": [],
      "source": [
        "DIR = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eTol7zkpNpx"
      },
      "outputs": [],
      "source": [
        "with open(DIR+ 'stratified_samples/' + fn + '_stratified_sample.json', 'r') as file:\n",
        "    graphs = [nx.node_link_graph(g) for g in json.load(file)]\n",
        "    roots = [g.graph['root'] for g in graphs]\n",
        "    nodes_list = [list(g.nodes.data('type')) for g in graphs]\n",
        "    graph_labels = [n[1] for i in range(len(graphs)) for n in nodes_list[i] if n[0]== roots[i]] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHUgpy_Rx3BN"
      },
      "outputs": [],
      "source": [
        "# normalize nodes ids\n",
        "for graph in graphs:\n",
        "  mapping = {n: i for i,n in enumerate(graph.nodes)}\n",
        "  nx.relabel_nodes(graph, mapping, copy=False)\n",
        "\n",
        "# normalize node labels (type)\n",
        "all_node_labels = sorted(set(t for g in graphs for _,t in g.nodes.data('type')))\n",
        "mapping = pd.get_dummies(pd.Series(all_node_labels))\n",
        "for graph in graphs:\n",
        "  for n,t in graph.nodes.data('type'):\n",
        "    graph.nodes[n]['feature'] = mapping[t]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdDdYZpfq0R_"
      },
      "outputs": [],
      "source": [
        "graph_labels = pd.Series(graph_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASL3DJNVgroO"
      },
      "outputs": [],
      "source": [
        "stellar_graphs = [StellarGraph.from_networkx(graphs[i], node_features=\"feature\", edge_type_attr=\"key\") for i in range(len(graphs))]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJAHP8ZgQREh"
      },
      "source": [
        "Saving dataset label for each graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joOE8_23rbbR"
      },
      "outputs": [],
      "source": [
        "graph_labels = pd.get_dummies(graph_labels, drop_first=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYmefr7ZjB-J"
      },
      "source": [
        "### Prepare graph generator\n",
        "\n",
        "To feed data to the `tf.Keras` model that we will create later, we need a data generator. For supervised graph classification, we create an instance of `StellarGraph`'s `PaddedGraphGenerator` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izMyLe67jB-J"
      },
      "outputs": [],
      "source": [
        "generator = PaddedGraphGenerator(graphs=stellar_graphs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_syPBD5ujB-L"
      },
      "source": [
        "### Create the Keras graph classification model\n",
        "\n",
        "We are now ready to create a `tf.Keras` graph classification model using `StellarGraph`'s `DeepGraphCNN` class together with standard `tf.Keras` layers `Conv1D`, `MapPool1D`, `Dropout`, and `Dense`. \n",
        "\n",
        "The model's input is the graph represented by its adjacency and node features matrices. The first four layers are Graph Convolutional as in [2] but using the adjacency normalisation from [1], $D^{-1}A$ where $A$ is the adjacency matrix with self loops and $D$ is the corresponding degree matrix. The graph convolutional layers each have 32, 32, 32, 1 units and `tanh` activations. \n",
        "\n",
        "The next layer is a one dimensional convolutional layer, `Conv1D`, followed by a max pooling, `MaxPool1D`, layer. Next is a second `Conv1D` layer that is followed by two `Dense` layers the second used for binary classification. The convolutional and dense layers use `relu` activation except for the last dense layer that uses `sigmoid` for classification. As described in [1], we add a `Dropout` layer after the first `Dense` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MqlLIQUjB-M"
      },
      "source": [
        "First we create the base DGCNN model that includes the graph convolutional and `SortPooling` layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eydqsdVjB-N",
        "outputId": "72291f80-a585-4669-f11e-e93d053d5163"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:617: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n"
          ]
        }
      ],
      "source": [
        "k = 35  # the number of rows for the output tensor\n",
        "layer_sizes = [32, 32, 32, 10]\n",
        "\n",
        "dgcnn_model = DeepGraphCNN(\n",
        "    layer_sizes=layer_sizes,\n",
        "    activations=[\"tanh\", \"tanh\", \"tanh\", \"tanh\"],\n",
        "    k=k,\n",
        "    bias=False,\n",
        "    generator=generator,\n",
        ")\n",
        "x_inp, x_out = dgcnn_model.in_out_tensors()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ekxeuIijB-O"
      },
      "source": [
        "Next, we add the convolutional, max pooling, and dense layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-GcLg3sjB-O"
      },
      "outputs": [],
      "source": [
        "x_out = Conv1D(filters=16, kernel_size=sum(layer_sizes), strides=sum(layer_sizes))(x_out)\n",
        "x_out = MaxPool1D(pool_size=2)(x_out)\n",
        "\n",
        "x_out = Conv1D(filters=32, kernel_size=5, strides=1)(x_out)\n",
        "\n",
        "x_out = Flatten()(x_out)\n",
        "\n",
        "x_out = Dense(units=128, activation=\"relu\")(x_out) \n",
        "x_out = Dropout(rate=0.5)(x_out)\n",
        "\n",
        "predictions = Dense(units=1, activation=\"sigmoid\")(x_out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5LFA5D8jB-P"
      },
      "source": [
        "Finally, we create the `Keras` model and prepare it for training by specifying the loss and optimisation algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZv7RKpmjB-Q",
        "outputId": "18467ee6-eeee-4a17-c897-77a51d174412"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ],
      "source": [
        "model = Model(inputs=x_inp, outputs=predictions)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(lr=0.0001), loss=binary_crossentropy, metrics=[\"acc\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TKfqXdYjB-Q"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qEQt0d0jB-R"
      },
      "outputs": [],
      "source": [
        "train_graphs, test_graphs = model_selection.train_test_split(\n",
        "    graph_labels, train_size=0.7, test_size=None, stratify=graph_labels,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgCx338OjB-S"
      },
      "source": [
        "Given the data split into train and test sets, we create a `StellarGraph.PaddedGenerator` generator object that prepares the data for training. We create data generators suitable for training at `tf.keras` model by calling the latter generator's `flow` method specifying the train and test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRkr2JtOjB-S"
      },
      "outputs": [],
      "source": [
        "gen = PaddedGraphGenerator(graphs=stellar_graphs)\n",
        "\n",
        "train_gen = gen.flow(\n",
        "    list(train_graphs.index - 1),\n",
        "    targets=train_graphs.values,\n",
        "    batch_size=50,\n",
        "    symmetric_normalization=False,\n",
        ")\n",
        "\n",
        "test_gen = gen.flow(\n",
        "    list(test_graphs.index - 1),\n",
        "    targets=test_graphs.values,\n",
        "    batch_size=1,\n",
        "    symmetric_normalization=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytOhQ0wujB-S"
      },
      "source": [
        "**Note**: We set the number of epochs to a large value so the call to `model.fit(...)` later might take a long time to complete. For faster performance set `epochs` to a smaller value; but if you do accuracy of the model found may be low."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmFa2ymDjB-T",
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "epochs = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1TQGhb1jB-T"
      },
      "source": [
        "We can now train the model by calling it's `fit` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYM28ztZjB-U",
        "outputId": "8dfafda0-f592-405e-d0cf-7f8d8a29afa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/sort_pooling/map/while/gradients/model/sort_pooling/map/while/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/sort_pooling/map/while/gradients/model/sort_pooling/map/while/GatherV2_grad/Reshape:0\", shape=(None, None), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/sort_pooling/map/while/gradients/model/sort_pooling/map/while/GatherV2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 4s 96ms/step - loss: 0.6873 - acc: 0.7440 - val_loss: 0.6776 - val_acc: 0.9307\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 1s 71ms/step - loss: 0.6665 - acc: 0.9323 - val_loss: 0.6506 - val_acc: 0.9335\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 1s 67ms/step - loss: 0.6310 - acc: 0.9335 - val_loss: 0.6049 - val_acc: 0.9335\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 1s 71ms/step - loss: 0.5756 - acc: 0.9335 - val_loss: 0.5355 - val_acc: 0.9335\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 1s 72ms/step - loss: 0.4930 - acc: 0.9335 - val_loss: 0.4463 - val_acc: 0.9335\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 1s 72ms/step - loss: 0.4048 - acc: 0.9335 - val_loss: 0.3565 - val_acc: 0.9335\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 1s 72ms/step - loss: 0.3261 - acc: 0.9335 - val_loss: 0.2923 - val_acc: 0.9335\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 1s 70ms/step - loss: 0.2800 - acc: 0.9335 - val_loss: 0.2630 - val_acc: 0.9335\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 1s 71ms/step - loss: 0.2634 - acc: 0.9335 - val_loss: 0.2538 - val_acc: 0.9335\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 1s 64ms/step - loss: 0.2585 - acc: 0.9335 - val_loss: 0.2509 - val_acc: 0.9335\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 1s 70ms/step - loss: 0.2563 - acc: 0.9335 - val_loss: 0.2493 - val_acc: 0.9335\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 1s 68ms/step - loss: 0.2536 - acc: 0.9335 - val_loss: 0.2481 - val_acc: 0.9335\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 1s 66ms/step - loss: 0.2537 - acc: 0.9335 - val_loss: 0.2473 - val_acc: 0.9335\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 1s 67ms/step - loss: 0.2530 - acc: 0.9335 - val_loss: 0.2467 - val_acc: 0.9335\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 1s 72ms/step - loss: 0.2520 - acc: 0.9335 - val_loss: 0.2463 - val_acc: 0.9335\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 1s 67ms/step - loss: 0.2515 - acc: 0.9335 - val_loss: 0.2460 - val_acc: 0.9335\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 1s 73ms/step - loss: 0.2514 - acc: 0.9335 - val_loss: 0.2457 - val_acc: 0.9335\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 1s 66ms/step - loss: 0.2503 - acc: 0.9335 - val_loss: 0.2456 - val_acc: 0.9335\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 1s 72ms/step - loss: 0.2517 - acc: 0.9335 - val_loss: 0.2454 - val_acc: 0.9335\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 1s 72ms/step - loss: 0.2504 - acc: 0.9335 - val_loss: 0.2453 - val_acc: 0.9335\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 1s 70ms/step - loss: 0.2515 - acc: 0.9335 - val_loss: 0.2452 - val_acc: 0.9335\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 1s 66ms/step - loss: 0.2497 - acc: 0.9335 - val_loss: 0.2450 - val_acc: 0.9335\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 1s 65ms/step - loss: 0.2500 - acc: 0.9335 - val_loss: 0.2450 - val_acc: 0.9335\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 1s 73ms/step - loss: 0.2510 - acc: 0.9335 - val_loss: 0.2449 - val_acc: 0.9335\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 1s 72ms/step - loss: 0.2498 - acc: 0.9335 - val_loss: 0.2448 - val_acc: 0.9335\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 1s 70ms/step - loss: 0.2498 - acc: 0.9335 - val_loss: 0.2448 - val_acc: 0.9335\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 1s 72ms/step - loss: 0.2494 - acc: 0.9335 - val_loss: 0.2447 - val_acc: 0.9335\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 1s 73ms/step - loss: 0.2506 - acc: 0.9335 - val_loss: 0.2447 - val_acc: 0.9335\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 1s 73ms/step - loss: 0.2500 - acc: 0.9335 - val_loss: 0.2447 - val_acc: 0.9335\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 1s 73ms/step - loss: 0.2500 - acc: 0.9335 - val_loss: 0.2447 - val_acc: 0.9335\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 1s 73ms/step - loss: 0.2500 - acc: 0.9335 - val_loss: 0.2446 - val_acc: 0.9335\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 2s 120ms/step - loss: 0.2497 - acc: 0.9335 - val_loss: 0.2446 - val_acc: 0.9335\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 1s 75ms/step - loss: 0.2496 - acc: 0.9335 - val_loss: 0.2446 - val_acc: 0.9335\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 1s 70ms/step - loss: 0.2490 - acc: 0.9335 - val_loss: 0.2446 - val_acc: 0.9335\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 1s 71ms/step - loss: 0.2494 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 1s 73ms/step - loss: 0.2490 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 1s 73ms/step - loss: 0.2495 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 1s 69ms/step - loss: 0.2494 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 1s 73ms/step - loss: 0.2489 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 1s 72ms/step - loss: 0.2491 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 1s 69ms/step - loss: 0.2494 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 1s 68ms/step - loss: 0.2493 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 1s 73ms/step - loss: 0.2489 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 1s 68ms/step - loss: 0.2486 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 1s 73ms/step - loss: 0.2489 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 1s 74ms/step - loss: 0.2492 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 1s 69ms/step - loss: 0.2493 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 1s 74ms/step - loss: 0.2490 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 1s 71ms/step - loss: 0.2489 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 1s 68ms/step - loss: 0.2489 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 1s 74ms/step - loss: 0.2485 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 1s 69ms/step - loss: 0.2490 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 1s 73ms/step - loss: 0.2485 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 1s 69ms/step - loss: 0.2486 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 1s 75ms/step - loss: 0.2489 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 1s 72ms/step - loss: 0.2486 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 1s 74ms/step - loss: 0.2484 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 1s 74ms/step - loss: 0.2488 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 1s 74ms/step - loss: 0.2489 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 1s 74ms/step - loss: 0.2489 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 1s 73ms/step - loss: 0.2483 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 1s 68ms/step - loss: 0.2488 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 1s 72ms/step - loss: 0.2487 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 1s 73ms/step - loss: 0.2478 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 1s 69ms/step - loss: 0.2485 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 1s 70ms/step - loss: 0.2490 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 1s 67ms/step - loss: 0.2488 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 1s 71ms/step - loss: 0.2480 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 1s 74ms/step - loss: 0.2479 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 1s 73ms/step - loss: 0.2485 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 1s 73ms/step - loss: 0.2487 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 1s 72ms/step - loss: 0.2489 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 1s 73ms/step - loss: 0.2485 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 1s 72ms/step - loss: 0.2485 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 1s 72ms/step - loss: 0.2474 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 1s 67ms/step - loss: 0.2479 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 1s 73ms/step - loss: 0.2493 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 1s 72ms/step - loss: 0.2483 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 1s 71ms/step - loss: 0.2484 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 1s 72ms/step - loss: 0.2482 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 1s 69ms/step - loss: 0.2492 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 1s 74ms/step - loss: 0.2484 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 1s 74ms/step - loss: 0.2483 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 1s 72ms/step - loss: 0.2485 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 1s 71ms/step - loss: 0.2484 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 1s 74ms/step - loss: 0.2484 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 1s 75ms/step - loss: 0.2483 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 1s 73ms/step - loss: 0.2490 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 1s 70ms/step - loss: 0.2484 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 1s 74ms/step - loss: 0.2483 - acc: 0.9335 - val_loss: 0.2445 - val_acc: 0.9335\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 1s 72ms/step - loss: 0.2486 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 1s 72ms/step - loss: 0.2483 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 1s 72ms/step - loss: 0.2489 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 1s 67ms/step - loss: 0.2494 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 1s 70ms/step - loss: 0.2484 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 1s 73ms/step - loss: 0.2477 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 1s 70ms/step - loss: 0.2485 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 1s 73ms/step - loss: 0.2473 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 1s 73ms/step - loss: 0.2478 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 1s 66ms/step - loss: 0.2476 - acc: 0.9335 - val_loss: 0.2444 - val_acc: 0.9335\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_gen, epochs=epochs, verbose=1, validation_data=test_gen, shuffle=True,\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEcxLa4WjB-U"
      },
      "source": [
        "Let us plot the training history (losses and accuracies for the train and test data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "AOl8BkmXjB-V",
        "outputId": "a1a25efd-d8f5-4329-c86f-cd4c936ee137"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "sg.utils.plot_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cStxIkVfjB-V"
      },
      "source": [
        "Finally, let us calculate the performance of the trained model on the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3yzt5NUjB-W",
        "outputId": "2308010c-2155-4180-fa4e-640de5d882c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "306/306 [==============================] - 1s 2ms/step - loss: 0.2444 - acc: 0.9335\n",
            "\n",
            "Test Set Metrics:\n",
            "\tloss: 0.2444\n",
            "\tacc: 0.9335\n"
          ]
        }
      ],
      "source": [
        "test_metrics = model.evaluate(test_gen)\n",
        "print(\"\\nTest Set Metrics:\")\n",
        "for name, val in zip(model.metrics_names, test_metrics):\n",
        "    print(\"\\t{}: {:0.4f}\".format(name, val))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DGCNN.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}